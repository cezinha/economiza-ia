# GUIA DO DATASET SINTÃ‰TICO - ECONOMIZA+

## ğŸ“Š RESUMO DO DATASET GERADO

### EstatÃ­sticas Principais:
- **500 usuÃ¡rios** (classes C e D)
- **194.231 transaÃ§Ãµes** (6 meses de histÃ³rico)
- **2.500 registros mensais** agregados
- **~74% dos usuÃ¡rios** com saldo negativo (realista!)
- **5% de anomalias** injetadas para treino do detector

---

## ğŸ“ ARQUIVOS GERADOS

### 1. `usuarios.csv` (500 linhas)
Perfil demogrÃ¡fico e financeiro de cada usuÃ¡rio.

**Colunas:**
- `user_id`: Identificador Ãºnico (user_0001 a user_0500)
- `idade`: 26-60 anos (distribuiÃ§Ã£o baseada em dados Serasa)
- `tipo_emprego`: CLT (45%), AutÃ´nomo (35%), Informal (20%)
- `renda_base`: R$ 2.000 - 4.500 (mÃ©dia R$ 3.080)
- `variabilidade_renda`: 0.05 (CLT) ou 0.35 (AutÃ´nomos)
- `estado_civil`: Solteiro, Casado, Divorciado
- `num_dependentes`: 0-3 filhos/dependentes
- `situacao_financeira`: Equilibrado, Endividado_Leve, Endividado_Grave, Inadimplente
- `regiao`: Sudeste, Sul, Nordeste, Centro-Oeste, Norte

**Exemplo de uso:**
```python
import pandas as pd

# Carregar usuÃ¡rios
usuarios = pd.read_csv('usuarios.csv')

# Ver distribuiÃ§Ã£o de renda por tipo de emprego
usuarios.groupby('tipo_emprego')['renda_base'].describe()

# Filtrar apenas usuÃ¡rios equilibrados
equilibrados = usuarios[usuarios['situacao_financeira'] == 'Equilibrado']
```

---

### 2. `transacoes.csv` (194.231 linhas)
Todas as transaÃ§Ãµes de todos os usuÃ¡rios em 6 meses.

**Colunas:**
- `user_id`: ID do usuÃ¡rio
- `data`: Data da transaÃ§Ã£o (jul/2025 a dez/2025)
- `categoria`: 12 categorias + Renda
  - **Essenciais**: Alimentacao_Casa, Habitacao_Aluguel, Habitacao_Contas, Transporte, Saude, Educacao, Telecomunicacoes, Higiene_Limpeza
  - **NÃ£o essenciais**: Alimentacao_Fora, Vestuario, Lazer, Outros
  - **Renda**: Entrada de dinheiro (positivo)
- `valor`: Valor em reais (R$)
- `mes`: MÃªs da transaÃ§Ã£o (1-12)
- `ano`: Ano (2025)
- `renda_mes`: Renda do usuÃ¡rio naquele mÃªs
- `is_essencial`: True/False
- `is_anomalia`: True/False (5% das transaÃ§Ãµes sÃ£o anomalias)

**CaracterÃ­sticas especiais:**
- **Sazonalidade**: Dezembro tem gastos 30% maiores (festas)
- **Variabilidade realista**: Categorias nÃ£o essenciais variam atÃ© 60%
- **Anomalias injetadas**: 5% das transaÃ§Ãµes tÃªm valores 3-8x maiores que o normal

**Exemplo de uso:**
```python
# Carregar transaÃ§Ãµes
transacoes = pd.read_csv('transacoes.csv')
transacoes['data'] = pd.to_datetime(transacoes['data'])

# Filtrar apenas gastos (remover renda)
gastos = transacoes[transacoes['categoria'] != 'Renda']

# Ver anomalias
anomalias = gastos[gastos['is_anomalia'] == True]
print(f"Total de anomalias: {len(anomalias)}")

# Gastos por categoria
gastos.groupby('categoria')['valor'].agg(['sum', 'mean', 'count'])

# SÃ©ries temporais de um usuÃ¡rio
user_001 = transacoes[transacoes['user_id'] == 'user_0001']
user_001.groupby('data')['valor'].sum().plot()
```

---

### 3. `estatisticas_mensais.csv` (2.500 linhas)
AgregaÃ§Ãµes mensais por usuÃ¡rio (500 usuÃ¡rios Ã— 5 meses).

**Colunas:**
- `user_id`: ID do usuÃ¡rio
- `ano`, `mes`: ReferÃªncia temporal
- `gasto_total`: Soma de todos os gastos do mÃªs
- `gasto_medio`: MÃ©dia dos valores das transaÃ§Ãµes
- `gasto_std`: Desvio padrÃ£o dos gastos
- `num_transacoes`: Quantidade de transaÃ§Ãµes no mÃªs
- `pct_essencial`: % de transaÃ§Ãµes essenciais
- `num_anomalias`: Quantidade de anomalias detectadas
- `renda_mes`: Renda do usuÃ¡rio no mÃªs
- `saldo_mes`: renda_mes - gasto_total (pode ser negativo!)
- `pct_gasto`: (gasto_total / renda_mes) Ã— 100

**Exemplo de uso:**
```python
# Carregar estatÃ­sticas
stats = pd.read_csv('estatisticas_mensais.csv')

# UsuÃ¡rios com gasto > renda
endividados = stats[stats['pct_gasto'] > 100]
print(f"{len(endividados)/len(stats)*100:.1f}% dos meses com gasto > renda")

# EvoluÃ§Ã£o temporal de um usuÃ¡rio
import matplotlib.pyplot as plt

user_stats = stats[stats['user_id'] == 'user_0001']
plt.plot(user_stats['mes'], user_stats['saldo_mes'])
plt.title('Saldo Mensal - User 0001')
plt.show()
```

---

## ğŸ¯ COMO USAR NO SEU PROJETO

### SPRINT 1: EDA e Clustering

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

# 1. CARREGAR DADOS
usuarios = pd.read_csv('usuarios.csv')
transacoes = pd.read_csv('transacoes.csv')
stats = pd.read_csv('estatisticas_mensais.csv')

# 2. CRIAR FEATURES PARA CLUSTERING
# Agregar por usuÃ¡rio
features_clustering = stats.groupby('user_id').agg({
    'renda_mes': 'mean',
    'gasto_total': 'mean',
    'gasto_std': 'mean',
    'pct_gasto': 'mean',
    'num_transacoes': 'mean',
    'pct_essencial': 'mean',
    'num_anomalias': 'sum'
}).reset_index()

# Merge com dados demogrÃ¡ficos
features_clustering = features_clustering.merge(
    usuarios[['user_id', 'idade', 'num_dependentes', 'variabilidade_renda']], 
    on='user_id'
)

# 3. NORMALIZAR
scaler = StandardScaler()
X = scaler.fit_transform(features_clustering.drop('user_id', axis=1))

# 4. APLICAR K-MEANS
kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(X)
features_clustering['cluster'] = clusters

# 5. ANALISAR CLUSTERS
print(features_clustering.groupby('cluster').mean())
```

### SPRINT 2: Sistema de RecomendaÃ§Ã£o

```python
# Identificar oportunidades de economia por cluster
def recomendar_economia(user_id, cluster_id):
    # Pegar gastos do usuÃ¡rio
    user_gastos = transacoes[
        (transacoes['user_id'] == user_id) & 
        (transacoes['categoria'] != 'Renda')
    ]
    
    # MÃ©dia do cluster
    cluster_users = features_clustering[
        features_clustering['cluster'] == cluster_id
    ]['user_id']
    
    cluster_gastos = transacoes[
        (transacoes['user_id'].isin(cluster_users)) &
        (transacoes['categoria'] != 'Renda')
    ]
    
    # Comparar por categoria
    user_por_cat = user_gastos.groupby('categoria')['valor'].sum()
    cluster_por_cat = cluster_gastos.groupby('categoria')['valor'].mean()
    
    # Identificar onde usuÃ¡rio gasta mais que a mÃ©dia
    oportunidades = (user_por_cat - cluster_por_cat).sort_values(ascending=False)
    
    return oportunidades[oportunidades > 0]
```

### SPRINT 2: DetecÃ§Ã£o de Anomalias

```python
from sklearn.ensemble import IsolationForest

# Treinar detector por categoria
def treinar_detector_anomalias(categoria):
    gastos_cat = transacoes[transacoes['categoria'] == categoria]
    
    # Features
    X = gastos_cat[['valor']].values
    
    # Treinar
    detector = IsolationForest(contamination=0.05, random_state=42)
    detector.fit(X)
    
    return detector

# Aplicar
detectors = {}
for cat in transacoes['categoria'].unique():
    if cat != 'Renda':
        detectors[cat] = treinar_detector_anomalias(cat)
```

---

## ğŸ” VALIDAÃ‡ÃƒO DO DATASET

### Checklist de Qualidade:

âœ… **DistribuiÃ§Ã£o de renda realista**: MÃ©dia R$ 3.080 (compatÃ­vel com classes C/D)
âœ… **Taxa de endividamento**: ~74% com saldo negativo (prÃ³ximo aos 79,5% da CNC)
âœ… **Variabilidade de renda**: CLT estÃ¡vel, autÃ´nomos variÃ¡veis
âœ… **Categorias baseadas em POF-IBGE**: Pesos realistas
âœ… **Sazonalidade**: Dezembro com gastos maiores
âœ… **Anomalias controladas**: 5% para treino do detector

---

## ğŸ’¡ DICAS E BOAS PRÃTICAS

### 1. **Sempre filtrar a categoria "Renda"**
```python
# Correto: apenas gastos
gastos = transacoes[transacoes['categoria'] != 'Renda']
```

### 2. **Usar `estatisticas_mensais.csv` para clustering**
Ã‰ mais eficiente que agregar `transacoes.csv` toda vez.

### 3. **Validar com dados reais posteriormente**
Este dataset Ã© sintÃ©tico. Compare padrÃµes com POF-IBGE quando possÃ­vel.

### 4. **Ajustar parÃ¢metros se necessÃ¡rio**
Edite o script `gerar_dataset_financeiro.py` e rode novamente:
```python
NUM_USUARIOS = 1000  # Aumentar para 1000
NUM_MESES = 12       # Aumentar histÃ³rico
```

### 5. **Documentar premissas**
No seu notebook, sempre documente:
- Quais features usou para clustering
- Por que escolheu determinado threshold
- Como tratou valores negativos

---

## ğŸ“š REFERÃŠNCIAS DOS DADOS

### Dados Reais Usados como Base:
- **Serasa** (Nov/2025): 80,6M inadimplentes, dÃ­vida mÃ©dia R$ 4.042
- **CNC** (Out/2025): 79,5% famÃ­lias endividadas, 30,5% inadimplentes
- **IBGE**: 60% nÃ£o conseguem poupar, POF (Pesquisa de OrÃ§amentos Familiares)

### Categorias baseadas em:
- **POF-IBGE 2017-2018**: Pesos das categorias de despesa
- **DistribuiÃ§Ã£o de renda**: Faixas salariais classes C e D

---

## ğŸš€ PRÃ“XIMOS PASSOS

1. **Sprint 1 (Dias 1-7)**:
   - Carregar datasets
   - EDA completo (estatÃ­sticas, visualizaÃ§Ãµes)
   - Feature Engineering
   - Clustering (K-means)

2. **Sprint 2 (Dias 8-14)**:
   - Sistema de recomendaÃ§Ã£o
   - DetecÃ§Ã£o de anomalias (Isolation Forest)

3. **Sprint 3 (Dias 15-21)**:
   - IntegraÃ§Ã£o dos modelos
   - Dashboard Streamlit
   - DocumentaÃ§Ã£o final

---

## â“ FAQ

**P: Posso usar dados reais?**
R: NÃ£o para o MVP. LGPD impede o uso de dados reais sem consentimento. Use este dataset sintÃ©tico.

**P: Como validar se os modelos funcionam?**
R: Use as mÃ©tricas definidas no projeto (Silhouette > 0.5, Precision > 0.85, etc.)

**P: E se eu quiser mais usuÃ¡rios?**
R: Edite `NUM_USUARIOS = 1000` no script e rode novamente.

**P: As anomalias estÃ£o marcadas?**
R: Sim! Coluna `is_anomalia = True`. Use para validar seu detector.

**P: Por que 74% tÃªm saldo negativo?**
R: Ã‰ realista! 79,5% das famÃ­lias brasileiras estÃ£o endividadas (CNC).

---

**Boa sorte no seu projeto!** ğŸš€
