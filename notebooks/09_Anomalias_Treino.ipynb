{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Deteccao de Anomalias: Treino\n",
    "## Sprint 2 - Dia 10\n",
    "\n",
    "**Objetivo:** Treinar detector de anomalias com Isolation Forest\n",
    "\n",
    "**Hipotese H6:** Isolation Forest detecta anomalias com Precision >0.85 e Recall >0.80\n",
    "\n",
    "**Restricao:** Modelo global (nao por categoria)\n",
    "\n",
    "**Entregaveis:**\n",
    "- Modelo `isolation_forest.pkl` treinado\n",
    "- Predicoes de anomalias para todo o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Configuracoes\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar transacoes\n",
    "transacoes = pd.read_csv('../data/raw/transacoes.csv')\n",
    "\n",
    "print(f\"Total de transacoes: {len(transacoes)}\")\n",
    "print(f\"\\nColunas: {list(transacoes.columns)}\")\n",
    "print(f\"\\nDistribuicao de anomalias (ground truth):\")\n",
    "print(transacoes['is_anomalia'].value_counts())\n",
    "print(f\"\\nPercentual de anomalias: {transacoes['is_anomalia'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas gastos (excluir Renda)\n",
    "gastos = transacoes[transacoes['categoria'] != 'Renda'].copy()\n",
    "\n",
    "print(f\"Transacoes de gasto: {len(gastos)}\")\n",
    "print(f\"Anomalias em gastos: {gastos['is_anomalia'].sum()}\")\n",
    "print(f\"Percentual: {gastos['is_anomalia'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analise Exploratoria das Anomalias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar valores normais vs anomalias\n",
    "print(\"=\"*70)\n",
    "print(\"COMPARACAO: TRANSACOES NORMAIS vs ANOMALIAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "normais = gastos[gastos['is_anomalia'] == False]['valor']\n",
    "anomalias = gastos[gastos['is_anomalia'] == True]['valor']\n",
    "\n",
    "print(f\"\\nTransacoes Normais:\")\n",
    "print(f\"  Count: {len(normais)}\")\n",
    "print(f\"  Media: R$ {normais.mean():.2f}\")\n",
    "print(f\"  Mediana: R$ {normais.median():.2f}\")\n",
    "print(f\"  Std: R$ {normais.std():.2f}\")\n",
    "print(f\"  Max: R$ {normais.max():.2f}\")\n",
    "\n",
    "print(f\"\\nTransacoes Anomalas:\")\n",
    "print(f\"  Count: {len(anomalias)}\")\n",
    "print(f\"  Media: R$ {anomalias.mean():.2f}\")\n",
    "print(f\"  Mediana: R$ {anomalias.median():.2f}\")\n",
    "print(f\"  Std: R$ {anomalias.std():.2f}\")\n",
    "print(f\"  Max: R$ {anomalias.max():.2f}\")\n",
    "\n",
    "print(f\"\\nRatio (anomalia/normal): {anomalias.mean()/normais.mean():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuicao de valores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histograma\n",
    "axes[0].hist(normais, bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "axes[0].hist(anomalias, bins=50, alpha=0.7, label='Anomalia', color='red')\n",
    "axes[0].set_xlabel('Valor (R$)')\n",
    "axes[0].set_ylabel('Frequencia')\n",
    "axes[0].set_title('Distribuicao de Valores: Normal vs Anomalia')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(0, 2000)  # Limitar para melhor visualizacao\n",
    "\n",
    "# Boxplot\n",
    "gastos['tipo'] = gastos['is_anomalia'].map({True: 'Anomalia', False: 'Normal'})\n",
    "sns.boxplot(data=gastos, x='tipo', y='valor', ax=axes[1], palette=['blue', 'red'])\n",
    "axes[1].set_ylabel('Valor (R$)')\n",
    "axes[1].set_title('Boxplot: Normal vs Anomalia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/anomalias_distribuicao.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Grafico salvo: outputs/anomalias_distribuicao.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomalias por categoria\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANOMALIAS POR CATEGORIA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "anomalias_por_cat = gastos.groupby('categoria').agg({\n",
    "    'is_anomalia': ['sum', 'mean', 'count']\n",
    "}).round(4)\n",
    "anomalias_por_cat.columns = ['num_anomalias', 'pct_anomalias', 'total_transacoes']\n",
    "anomalias_por_cat['pct_anomalias'] = anomalias_por_cat['pct_anomalias'] * 100\n",
    "anomalias_por_cat = anomalias_por_cat.sort_values('num_anomalias', ascending=False)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(anomalias_por_cat.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering para Deteccao de Anomalias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular estatisticas por categoria para normalizar valores\n",
    "stats_categoria = gastos.groupby('categoria')['valor'].agg(['mean', 'std', 'median']).reset_index()\n",
    "stats_categoria.columns = ['categoria', 'media_cat', 'std_cat', 'mediana_cat']\n",
    "\n",
    "print(\"Estatisticas por categoria:\")\n",
    "print(stats_categoria.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge estatisticas com gastos\n",
    "gastos_features = gastos.merge(stats_categoria, on='categoria')\n",
    "\n",
    "# Criar features para o modelo\n",
    "# Feature 1: Valor absoluto\n",
    "gastos_features['feat_valor'] = gastos_features['valor']\n",
    "\n",
    "# Feature 2: Valor normalizado pela media da categoria (z-score simplificado)\n",
    "gastos_features['feat_valor_norm'] = (\n",
    "    (gastos_features['valor'] - gastos_features['media_cat']) / gastos_features['std_cat']\n",
    ")\n",
    "\n",
    "# Feature 3: Ratio valor/mediana da categoria\n",
    "gastos_features['feat_ratio_mediana'] = gastos_features['valor'] / gastos_features['mediana_cat']\n",
    "\n",
    "# Feature 4: Log do valor (para lidar com skewness)\n",
    "gastos_features['feat_log_valor'] = np.log1p(gastos_features['valor'])\n",
    "\n",
    "print(\"Features criadas:\")\n",
    "print(\"  - feat_valor: Valor absoluto\")\n",
    "print(\"  - feat_valor_norm: Z-score por categoria\")\n",
    "print(\"  - feat_ratio_mediana: Ratio valor/mediana da categoria\")\n",
    "print(\"  - feat_log_valor: Log do valor\")\n",
    "\n",
    "gastos_features[['valor', 'categoria', 'feat_valor', 'feat_valor_norm', 'feat_ratio_mediana', 'feat_log_valor', 'is_anomalia']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar correlacao das features com anomalias\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELACAO DAS FEATURES COM ANOMALIAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "features_cols = ['feat_valor', 'feat_valor_norm', 'feat_ratio_mediana', 'feat_log_valor']\n",
    "\n",
    "for feat in features_cols:\n",
    "    corr = gastos_features[feat].corr(gastos_features['is_anomalia'].astype(int))\n",
    "    print(f\"  {feat}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparacao dos Dados para Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar features para o modelo\n",
    "# Usando apenas feat_valor_norm e feat_ratio_mediana (mais discriminativas)\n",
    "FEATURES_MODELO = ['feat_valor_norm', 'feat_ratio_mediana']\n",
    "\n",
    "X = gastos_features[FEATURES_MODELO].copy()\n",
    "y_true = gastos_features['is_anomalia'].astype(int).values\n",
    "\n",
    "# Tratar valores infinitos ou NaN\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"Shape dos dados: {X.shape}\")\n",
    "print(f\"Features: {FEATURES_MODELO}\")\n",
    "print(f\"\\nEstatisticas das features:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar features com StandardScaler\n",
    "scaler_anomalias = StandardScaler()\n",
    "X_scaled = scaler_anomalias.fit_transform(X)\n",
    "\n",
    "print(\"Features normalizadas com StandardScaler\")\n",
    "print(f\"Shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Treinar Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros do modelo\n",
    "# contamination = proporcao esperada de anomalias (5% no dataset)\n",
    "CONTAMINATION = 0.05\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TREINAMENTO DO ISOLATION FOREST\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nParametros:\")\n",
    "print(f\"  - contamination: {CONTAMINATION}\")\n",
    "print(f\"  - n_estimators: 100 (default)\")\n",
    "print(f\"  - random_state: 42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo\n",
    "isolation_forest = IsolationForest(\n",
    "    contamination=CONTAMINATION,\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "isolation_forest.fit(X_scaled)\n",
    "\n",
    "print(\"\\nModelo treinado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar predicoes\n",
    "# Isolation Forest retorna: 1 para normal, -1 para anomalia\n",
    "y_pred_raw = isolation_forest.predict(X_scaled)\n",
    "\n",
    "# Converter para 0/1 (0=normal, 1=anomalia)\n",
    "y_pred = (y_pred_raw == -1).astype(int)\n",
    "\n",
    "print(f\"\\nPredicoes geradas:\")\n",
    "print(f\"  Normais detectados: {(y_pred == 0).sum()}\")\n",
    "print(f\"  Anomalias detectadas: {(y_pred == 1).sum()}\")\n",
    "print(f\"  Percentual anomalias: {y_pred.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter scores de anomalia (quanto menor, mais anomalo)\n",
    "anomaly_scores = isolation_forest.decision_function(X_scaled)\n",
    "\n",
    "# Adicionar ao dataframe\n",
    "gastos_features['anomaly_score'] = anomaly_scores\n",
    "gastos_features['pred_anomalia'] = y_pred\n",
    "\n",
    "print(\"Scores de anomalia calculados\")\n",
    "print(f\"\\nScore medio - Normais (ground truth): {gastos_features[gastos_features['is_anomalia']==False]['anomaly_score'].mean():.4f}\")\n",
    "print(f\"Score medio - Anomalias (ground truth): {gastos_features[gastos_features['is_anomalia']==True]['anomaly_score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avaliacao Preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular metricas\n",
    "print(\"=\"*70)\n",
    "print(\"AVALIACAO PRELIMINAR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n>>> PRECISION: {precision:.4f} (target: >0.85)\")\n",
    "print(f\">>> RECALL: {recall:.4f} (target: >0.80)\")\n",
    "print(f\">>> F1-SCORE: {f1:.4f}\")\n",
    "\n",
    "# Status\n",
    "precision_ok = precision >= 0.85\n",
    "recall_ok = recall >= 0.80\n",
    "\n",
    "print(f\"\\nStatus Precision: {'ATINGIDO' if precision_ok else 'NAO ATINGIDO'}\")\n",
    "print(f\"Status Recall: {'ATINGIDO' if recall_ok else 'NAO ATINGIDO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusao\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\nMatriz de Confusao:\")\n",
    "print(f\"                 Pred Normal  Pred Anomalia\")\n",
    "print(f\"Real Normal      {cm[0,0]:>10}  {cm[0,1]:>13}\")\n",
    "print(f\"Real Anomalia    {cm[1,0]:>10}  {cm[1,1]:>13}\")\n",
    "\n",
    "print(f\"\\nInterpretacao:\")\n",
    "print(f\"  True Negatives (TN): {cm[0,0]} - Normais corretamente identificados\")\n",
    "print(f\"  False Positives (FP): {cm[0,1]} - Normais classificados como anomalia\")\n",
    "print(f\"  False Negatives (FN): {cm[1,0]} - Anomalias nao detectadas\")\n",
    "print(f\"  True Positives (TP): {cm[1,1]} - Anomalias corretamente detectadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusao\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "            xticklabels=['Normal', 'Anomalia'],\n",
    "            yticklabels=['Normal', 'Anomalia'])\n",
    "ax.set_xlabel('Predicao')\n",
    "ax.set_ylabel('Real (Ground Truth)')\n",
    "ax.set_title(f'Matriz de Confusao - Isolation Forest\\nPrecision: {precision:.2%} | Recall: {recall:.2%}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/matriz_confusao_anomalias.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Grafico salvo: outputs/matriz_confusao_anomalias.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuicao dos scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "scores_normais = gastos_features[gastos_features['is_anomalia']==False]['anomaly_score']\n",
    "scores_anomalias = gastos_features[gastos_features['is_anomalia']==True]['anomaly_score']\n",
    "\n",
    "ax.hist(scores_normais, bins=50, alpha=0.7, label='Normal (ground truth)', color='blue')\n",
    "ax.hist(scores_anomalias, bins=50, alpha=0.7, label='Anomalia (ground truth)', color='red')\n",
    "ax.axvline(x=0, color='green', linestyle='--', label='Threshold (score=0)')\n",
    "ax.set_xlabel('Anomaly Score (menor = mais anomalo)')\n",
    "ax.set_ylabel('Frequencia')\n",
    "ax.set_title('Distribuicao dos Scores de Anomalia')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/distribuicao_scores_anomalia.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Grafico salvo: outputs/distribuicao_scores_anomalia.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Salvar Modelo e Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretorio models se nao existir\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Salvar modelo Isolation Forest\n",
    "with open('../models/isolation_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(isolation_forest, f)\n",
    "print(\"Modelo salvo: models/isolation_forest.pkl\")\n",
    "\n",
    "# Salvar scaler\n",
    "with open('../models/scaler_anomalias.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_anomalias, f)\n",
    "print(\"Scaler salvo: models/scaler_anomalias.pkl\")\n",
    "\n",
    "# Salvar estatisticas por categoria (necessario para novas predicoes)\n",
    "stats_categoria.to_csv('../models/stats_categoria_anomalias.csv', index=False)\n",
    "print(\"Estatisticas salvas: models/stats_categoria_anomalias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar transacoes com predicoes\n",
    "colunas_saida = [\n",
    "    'user_id', 'data', 'categoria', 'valor', 'mes', 'ano',\n",
    "    'is_essencial', 'is_anomalia', 'anomaly_score', 'pred_anomalia'\n",
    "]\n",
    "\n",
    "transacoes_com_pred = gastos_features[colunas_saida].copy()\n",
    "transacoes_com_pred.to_csv('../data/processed/transacoes_com_anomalias_pred.csv', index=False)\n",
    "\n",
    "print(f\"\\nTransacoes com predicoes salvas: data/processed/transacoes_com_anomalias_pred.csv\")\n",
    "print(f\"Total de linhas: {len(transacoes_com_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar configuracao do modelo\n",
    "import json\n",
    "\n",
    "config_modelo = {\n",
    "    'versao': '1.0',\n",
    "    'data_treino': '2026-01-26',\n",
    "    'modelo': 'IsolationForest',\n",
    "    'parametros': {\n",
    "        'contamination': CONTAMINATION,\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    'features': FEATURES_MODELO,\n",
    "    'metricas_treino': {\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1_score': round(f1, 4)\n",
    "    },\n",
    "    'targets': {\n",
    "        'precision': 0.85,\n",
    "        'recall': 0.80\n",
    "    },\n",
    "    'arquivos': {\n",
    "        'modelo': 'isolation_forest.pkl',\n",
    "        'scaler': 'scaler_anomalias.pkl',\n",
    "        'stats_categoria': 'stats_categoria_anomalias.csv'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../models/config_anomalias.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(config_modelo, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Configuracao salva: models/config_anomalias.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Funcao de Predicao para Novos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_anomalia(transacao, modelo, scaler, stats_cat):\n",
    "    \"\"\"\n",
    "    Detecta se uma transacao e anomala.\n",
    "    \n",
    "    Parametros:\n",
    "        transacao: dict com 'valor' e 'categoria'\n",
    "        modelo: IsolationForest treinado\n",
    "        scaler: StandardScaler treinado\n",
    "        stats_cat: DataFrame com estatisticas por categoria\n",
    "    \n",
    "    Retorna:\n",
    "        dict com 'is_anomalia', 'score', 'confianca'\n",
    "    \"\"\"\n",
    "    valor = transacao['valor']\n",
    "    categoria = transacao['categoria']\n",
    "    \n",
    "    # Buscar estatisticas da categoria\n",
    "    cat_stats = stats_cat[stats_cat['categoria'] == categoria]\n",
    "    \n",
    "    if len(cat_stats) == 0:\n",
    "        # Categoria desconhecida - usar media geral\n",
    "        media_cat = stats_cat['media_cat'].mean()\n",
    "        std_cat = stats_cat['std_cat'].mean()\n",
    "        mediana_cat = stats_cat['mediana_cat'].mean()\n",
    "    else:\n",
    "        media_cat = cat_stats['media_cat'].values[0]\n",
    "        std_cat = cat_stats['std_cat'].values[0]\n",
    "        mediana_cat = cat_stats['mediana_cat'].values[0]\n",
    "    \n",
    "    # Calcular features\n",
    "    feat_valor_norm = (valor - media_cat) / std_cat if std_cat > 0 else 0\n",
    "    feat_ratio_mediana = valor / mediana_cat if mediana_cat > 0 else 0\n",
    "    \n",
    "    # Preparar input\n",
    "    X = np.array([[feat_valor_norm, feat_ratio_mediana]])\n",
    "    X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Predicao\n",
    "    pred = modelo.predict(X_scaled)[0]\n",
    "    score = modelo.decision_function(X_scaled)[0]\n",
    "    \n",
    "    is_anomalia = pred == -1\n",
    "    \n",
    "    return {\n",
    "        'is_anomalia': is_anomalia,\n",
    "        'score': round(score, 4),\n",
    "        'confianca': 'alta' if abs(score) > 0.1 else 'media' if abs(score) > 0.05 else 'baixa'\n",
    "    }\n",
    "\n",
    "print(\"Funcao detectar_anomalia() definida!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar funcao com exemplos\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE DA FUNCAO DE DETECCAO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "exemplos = [\n",
    "    {'valor': 50.0, 'categoria': 'Alimentacao_Fora', 'descricao': 'Gasto normal'},\n",
    "    {'valor': 500.0, 'categoria': 'Alimentacao_Fora', 'descricao': 'Gasto alto'},\n",
    "    {'valor': 1500.0, 'categoria': 'Alimentacao_Fora', 'descricao': 'Gasto muito alto'},\n",
    "    {'valor': 100.0, 'categoria': 'Vestuario', 'descricao': 'Gasto normal'},\n",
    "    {'valor': 800.0, 'categoria': 'Vestuario', 'descricao': 'Gasto alto'},\n",
    "]\n",
    "\n",
    "for ex in exemplos:\n",
    "    resultado = detectar_anomalia(ex, isolation_forest, scaler_anomalias, stats_categoria)\n",
    "    status = \"ANOMALIA\" if resultado['is_anomalia'] else \"NORMAL\"\n",
    "    print(f\"\\n{ex['descricao']} - {ex['categoria']}: R$ {ex['valor']:.2f}\")\n",
    "    print(f\"  -> {status} (score: {resultado['score']}, confianca: {resultado['confianca']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Checklist e Proximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checklist Dia 10\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CHECKLIST DIA 10\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n[x] Carregar e analisar transacoes\")\n",
    "print(\"[x] Feature engineering para anomalias\")\n",
    "print(\"[x] Treinar Isolation Forest global\")\n",
    "print(\"[x] Gerar predicoes para todo o dataset\")\n",
    "print(\"[x] Avaliacao preliminar (precision, recall)\")\n",
    "print(\"[x] Salvar modelo e artefatos\")\n",
    "print(\"[x] Criar funcao de predicao para novos dados\")\n",
    "print(\"\\n>>> DIA 10 CONCLUIDO!\")\n",
    "print(\"\\nProximo passo (Dia 11): Validacao detalhada da H6 e ajustes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMO FINAL - DIA 10\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModelo: Isolation Forest\")\n",
    "print(f\"Features: {FEATURES_MODELO}\")\n",
    "print(f\"Contamination: {CONTAMINATION}\")\n",
    "print(f\"\\nMetricas preliminares:\")\n",
    "print(f\"  Precision: {precision:.4f} (target: >0.85) - {'OK' if precision_ok else 'AJUSTAR'}\")\n",
    "print(f\"  Recall: {recall:.4f} (target: >0.80) - {'OK' if recall_ok else 'AJUSTAR'}\")\n",
    "print(f\"  F1-Score: {f1:.4f}\")\n",
    "print(f\"\\nArquivos gerados:\")\n",
    "print(\"  - models/isolation_forest.pkl\")\n",
    "print(\"  - models/scaler_anomalias.pkl\")\n",
    "print(\"  - models/stats_categoria_anomalias.csv\")\n",
    "print(\"  - models/config_anomalias.json\")\n",
    "print(\"  - data/processed/transacoes_com_anomalias_pred.csv\")\n",
    "print(\"  - outputs/anomalias_distribuicao.png\")\n",
    "print(\"  - outputs/matriz_confusao_anomalias.png\")\n",
    "print(\"  - outputs/distribuicao_scores_anomalia.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "economiza-ia-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
